from bs4 import BeautifulSoup as bs
from lib.common import getContent
from lib.mongodb import operations
from lib.jobs_log import updateJobStatus
import re 

def parser(job):
    obj = operations()
    file_path = job['storage_path']
    content = getContent(file_path)
    soup = bs(content, 'html.parser')
    records = soup.find_all('div',{"class":"view-content"})[3]
    data = dict()
    data['job_id'] = job['job_id']
    data['doctor_name'] = ''
    for record in records.find_all("div",{"class":"box-content"}):
        print(record)
        print('**'*20)
    #obj.insert_one('in', job['collection'], data)

    #Log to database 
    #obj.closeConnection()
    #job['is_parsed'] = "True"
    #updateJobStatus(job['job_id'], job)

job = {'is_crawled': 'True', 'is_parsed': 'False', 
       'storage_id': 'd4da6fc798620a9d8c17cb7706b0ba34', 'extension': 'htm', 
       'insert_time': '', 'update_time': '', 'crawl_queue': '', 'parse_queue': '',
       'domain': 'treasurevalleyhospital.com', 'collection': 'treasurevalleyhospital',
       'job_script': 'jobs.treasurevalleyhospital.jobs', 'crawl_script': 'crawler.crawl.getPage',
       'parse_script': 'parser.treasurevalleyhospital.parser.parser', 'priorities': 'high', 
       'storage_path': '/Users/kamlesh/WorkSpace/simpleSpider/public/ecb32f69ddb240d2ac92e92167e8c1a5.htm', 
       'crawl_count': 0, 'input': {'url': 'https://treasurevalleyhospital.com/our-doctors'}, 
       'job_id': '0ee14140d64548ad8a1537a07e052c66'}

parser(job)
